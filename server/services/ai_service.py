import os
import json
import asyncio
from langchain_nvidia_ai_endpoints import ChatNVIDIA
from langchain_core.messages import HumanMessage, SystemMessage


class AIService:

    def __init__(self):
        # NVIDIA NIM ì—°ê²° ì„¤ì • (Secretsì— ë“±ë¡ëœ API Key ì‚¬ìš©)
        self.llm = ChatNVIDIA(model="meta/llama-3.2-11b-vision-instruct",
                              nvidia_api_key=os.getenv("NVIDIA_API_KEY"))

        # ì‹œê°ì¥ì• ì¸ ìˆ˜ê°•ìƒì„ ìœ„í•œ ì „ìš© í˜ë¥´ì†Œë‚˜ ë° ì¶œë ¥ ê·œê²© ì •ì˜
        self.system_prompt = """
        ë„ˆëŠ” ì‹œê°ì¥ì• ì¸ ìˆ˜ê°•ìƒì„ ìœ„í•´ ê°•ì˜ ì˜ìƒ ì† ê°•ì‚¬ì˜ ë™ì‘ì„ ë¶„ì„í•˜ê³  ì—ë””í„°ë¥¼ ì œì–´í•˜ëŠ” AI ì—ì´ì „íŠ¸ì•¼.
        ê°•ì˜ í™”ë©´(ì´ë¯¸ì§€)ì„ ë¶„ì„í•˜ì—¬ ìˆ˜ê°•ìƒì´ ë”°ë¼í•´ì•¼ í•  ë™ì‘ì„ íŒë‹¨í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´.

        [ëª…ë ¹ì–´ íƒ€ì… ê°€ì´ë“œ]
        - focus_window: ì°½ ì „í™˜ì´ í•„ìš”í•  ë•Œ (ì˜ˆ: ë¸Œë¼ìš°ì €ì—ì„œ VS Codeë¡œ)
        - hotkey: ë‹¨ì¶•í‚¤ ì‹¤í–‰ (ì˜ˆ: ['ctrl', 's'], ['ctrl', 'g'])
        - type_text: ì½”ë“œë‚˜ í…ìŠ¤íŠ¸ ì…ë ¥
        - goto_line: íŠ¹ì • ë¼ì¸ìœ¼ë¡œ ì´ë™
        - save_file: íŒŒì¼ ì €ì¥

        [ì‘ë‹µ í˜•ì‹]
        {
          "type": "ëª…ë ¹ì–´íƒ€ì…",
          "payload": { "í•´ë‹¹ ìŠ¤í‚¤ë§ˆì˜ í•„ë“œ" },
          "guidance": "ìŠ¤í¬ë¦°ë¦¬ë”ê°€ ì½ì–´ì¤„ ì¹œì ˆí•œ ì„¤ëª…",
          "should_pause": true/false
        }
        """

    async def analyze_and_decide(self, image_b64: str, local_status: str):
        """
        NVIDIA NIMì„ í†µí•´ í™”ë©´ì„ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”ëœ ì˜ì‚¬ê²°ì • ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        content = [{
            "type": "text",
            "text": f"í˜„ì¬ ë¡œì»¬ ìƒíƒœ: {local_status}. í™”ë©´ ë¶„ì„ í›„ í•„ìš”í•œ ëª…ë ¹ì„ ë‚´ë ¤ì¤˜."
        }, {
            "type": "image_url",
            "image_url": {
                "url": image_b64
            }
        }]

        try:
            response = await self.llm.ainvoke([
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=content)
            ])

            # AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±
            result = json.loads(response.content)
            return result
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                "type": "type_text",
                "payload": {},
                "guidance": "í™”ë©´ì„ ë¶„ì„í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "should_pause": True
            }

    async def test_ask(self, question: str):
        """ì—°ê²° í™•ì¸ìš© í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ"""
        try:
            response = await self.llm.ainvoke([
                SystemMessage(content="ë„ˆëŠ” ì¹œì ˆí•œ ë„ìš°ë¯¸ì•¼."),
                HumanMessage(content=question)
            ])
            return response.content
        except Exception as e:
            return f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"


if __name__ == "__main__":

    async def run_test():
        service = AIService()
        print("ğŸ” NVIDIA NIM ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        res = await service.test_ask("Hello, NIM!")
        print(f"ğŸ¤– ì‘ë‹µ: {res}")

    asyncio.run(run_test())
